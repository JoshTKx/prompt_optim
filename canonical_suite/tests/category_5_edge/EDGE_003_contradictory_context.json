{
  "id": "EDGE-003",
  "name": "Contradictory Context",
  "category": "edge",
  "archetype": "C3_ambiguity_handling",
  "difficulty": "hard",
  
  "task": {
    "description": "Test model's handling of contradictory information",
    "initial_prompt": "Answer based on the context provided.",
    "target_model": "gpt-4o-mini",
    "context": "The sky is green. The sky is blue."
  },
  
  "test_cases": [
    {
      "input": "What color is the sky?",
      "expected_output": {
        "type": "unstructured",
        "format": "text",
        "validation": "llm_judge",
        "constraints": [
          "identifies_contradiction",
          "handles_ambiguity"
        ]
      }
    }
  ],
  
  "evaluation": {
    "method": "llm_judge",
    "validators": ["contradiction_detector"],
    "rubric": "five_point_standard",
    "pass_criteria": {
      "minimum_score": 3
    }
  },
  
  "optimization_challenge": "Models may pick one side arbitrarily. Optimizer must prompt for contradiction identification.",
  
  "metadata": {
    "source": "Custom",
    "tags": ["edge", "contradiction", "reasoning"],
    "archetype_class": "C_reasoning",
    "domain": "general"
  }
}
